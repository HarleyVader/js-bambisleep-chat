model = "F5TTS_v1_Small"
audio_file = "data/reference_audio/bambi.wav"
output_format = "wav"
use_cuda = true
cuda_device = "0"  # Set to the appropriate CUDA device ID
sample_rate = 22050  # Sample rate for the audio
chunk_size = 1024  # Size of audio chunks for processing
max_length = 300  # Maximum length of generated text
temperature = 0.7  # Sampling temperature for text generation
top_k = 50  # Top-k sampling
top_p = 0.95  # Top-p (nucleus) sampling
use_fp16 = true  # Use half-precision for inference to save memory
logging_level = "INFO"  # Logging level for the inference process